{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true,
          "node_id": "0M2OGHiBtyMfy6XkEY0b6S",
          "type": "MD"
        },
        "id": "-QP8OFwL2Owd"
      },
      "source": [
        "# About üç≤Ô∏è\n",
        "\n",
        "**A recipe generator is a tool or software that uses algorithms to create unique recipes based on specific criteria such as ingredients, dietary restrictions, cooking methods, and cuisine preferences. These generators are designed to help individuals find new and interesting ways to prepare meals and provide inspiration for creating dishes they may not have considered before**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true,
          "node_id": "DDCAAnTXGa7aLMn790Sbr4",
          "type": "MD"
        },
        "id": "LrKtIu5S2Owe"
      },
      "source": [
        "## Importing  libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTRVtJ622XqH",
        "outputId": "efba27fe-e7c7-4d1e-ff2b-7733dbbf101a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x3hEDWN2umm",
        "outputId": "df454852-9bad-4639-d489-303add2d29cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4v9MxIx3RQe",
        "outputId": "4dd8d436-4e31-4356-9568-fe71bc99c6f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5wCQQHQ3evH",
        "outputId": "eb7f3b40-9c7e-4f6f-dbb8-3723e3f31e4f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0gXWsjd7X9c",
        "outputId": "d2357cc0-0aba-4cd5-fb88-2393b8c7aff0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "Rt0t99f14VIEUHhFyxjO8W",
          "report_properties": {
            "rowId": "Ddu94u6qzc0tMocTOV2t4V"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:48:53.330325Z",
          "iopub.status.busy": "2023-06-04T17:48:53.329537Z",
          "iopub.status.idle": "2023-06-04T17:49:03.721040Z",
          "shell.execute_reply": "2023-06-04T17:49:03.719915Z",
          "shell.execute_reply.started": "2023-06-04T17:48:53.330229Z"
        },
        "id": "OZWO3q5z2Owe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "import accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true,
          "node_id": "4a2IEWMpxL69gHBtrycBS3",
          "type": "MD"
        },
        "id": "eSpeAoC02Owf"
      },
      "source": [
        "## **Model configuration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "Gw28g2UgVOsEjuU4ontL2Y",
          "report_properties": {
            "rowId": "UA5cBMlo662l8joHq6zi2D"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:03.724770Z",
          "iopub.status.busy": "2023-06-04T17:49:03.723682Z",
          "iopub.status.idle": "2023-06-04T17:49:03.730225Z",
          "shell.execute_reply": "2023-06-04T17:49:03.728930Z",
          "shell.execute_reply.started": "2023-06-04T17:49:03.724726Z"
        },
        "id": "9aUS6knj2Owf"
      },
      "outputs": [],
      "source": [
        "model_name = 'gpt2'# Name of the pre-trained GPT2 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "4TpAVQr6YtElV2DhIuYfCG",
          "report_properties": {
            "rowId": "mwoENNvka6um4ZRoR61rsc"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:03.732790Z",
          "iopub.status.busy": "2023-06-04T17:49:03.732041Z",
          "iopub.status.idle": "2023-06-04T17:49:03.745324Z",
          "shell.execute_reply": "2023-06-04T17:49:03.744272Z",
          "shell.execute_reply.started": "2023-06-04T17:49:03.732754Z"
        },
        "id": "5jP6xBDO2Owf"
      },
      "outputs": [],
      "source": [
        "model_save_path = '/content/drive/MyDrive/major project' # Path to save the trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true,
          "node_id": "tmohMeDnmYgucw4jMwXOU5",
          "type": "MD"
        },
        "id": "tzsK6Xsq2Owf"
      },
      "source": [
        "## **Tokenizer initialization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "dKfCR80HNODcEgVEAFDBYD",
          "report_properties": {
            "rowId": "0e5nDha6BkgattyU6LnSHl"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:03.747658Z",
          "iopub.status.busy": "2023-06-04T17:49:03.746968Z",
          "iopub.status.idle": "2023-06-04T17:49:23.981448Z",
          "shell.execute_reply": "2023-06-04T17:49:23.980247Z",
          "shell.execute_reply.started": "2023-06-04T17:49:03.747621Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPbgBieh2Owg",
        "outputId": "25bd88f3-3c2c-4bbe-bab0-e88d9def59c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50260, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "tokenizer = GPT2TokenizerFast.from_pretrained(model_name,\n",
        "                                              bos_token='<|startoftext|>',# Beginning of sentence token\n",
        "                                              eos_token='<|endoftext|>',# End of sentence token\n",
        "                                              unk_token='<|unknown|>', # Unknown token\n",
        "                                              pad_token='<|pad|>'# Padding token\n",
        "                                             )\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)# Initialize the GPT2 model\n",
        "model.resize_token_embeddings(len(tokenizer))# Resize the token embeddings to match the tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true,
          "node_id": "uSmyzA3G8krLGqgYhE6fqa",
          "type": "MD"
        },
        "id": "Ad9bZo2I2Owh"
      },
      "source": [
        "**GPT2LMHeadModel is a pre-trained language model based on the GPT-2 architecture. It is designed to generate text by predicting the next word in a sequence given the previous words. It is called a \"language model\" because it models the probability distribution of words in a language.\n",
        "The \"LMHead\" in the name stands for \"Language Model Head\", which refers to the fact that the model is trained to predict the next word in a sequence. The \"Head\" part of the name is because this is the final layer of the model, which produces the output. In this specific code, the GPT2LMHeadModel is used to generate recipes by predicting the next word in the recipe based on the previous words.\n",
        "The Trainer is a class provided by the Hugging Face transformers library that is used to train and evaluate models. It provides an easy-to-use interface for training and fine-tuning models, including handling data loading, batching, and optimization.In this code, the Trainer is used to fine-tune the GPT2LMHeadModel on a custom recipe dataset. It takes care of training the model for a specified number of epochs, handling the batching of data, and applying the specified optimizer and learning rate scheduler.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "nAPyOlNeriLsBWTLs5lP5c",
          "report_properties": {
            "rowId": "eXKKZ3xa70ZakHgxyWHvpU"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:23.985454Z",
          "iopub.status.busy": "2023-06-04T17:49:23.985063Z",
          "iopub.status.idle": "2023-06-04T17:49:24.125018Z",
          "shell.execute_reply": "2023-06-04T17:49:24.124039Z",
          "shell.execute_reply.started": "2023-06-04T17:49:23.985415Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwL91HEy2Owh",
        "outputId": "ad6b9de1-ace6-4f4f-e02a-626dfcb3dbc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/major project/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/major project/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/major project/vocab.json',\n",
              " '/content/drive/MyDrive/major project/merges.txt',\n",
              " '/content/drive/MyDrive/major project/added_tokens.json',\n",
              " '/content/drive/MyDrive/major project/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tokenizer.save_pretrained(model_save_path)# Save the tokenizer to the specified model_save_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "4c9FRjKZnKjpo2AjCmx8i1",
          "report_properties": {
            "rowId": "CErXK2yFPUKZP3GVpB2fjG"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:24.127055Z",
          "iopub.status.busy": "2023-06-04T17:49:24.126456Z",
          "iopub.status.idle": "2023-06-04T17:49:25.911643Z",
          "shell.execute_reply": "2023-06-04T17:49:25.910623Z",
          "shell.execute_reply.started": "2023-06-04T17:49:24.127015Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbMsf-7d2Owh",
        "outputId": "37b4af22-01b4-4150-8511-9007ea39798e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[50259]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tokenizer.convert_tokens_to_ids(['<|pad|>'])# Convert the empty token to its corresponding token ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true,
          "node_id": "yQOmEQq5LQ2dFfYz3iXV9u",
          "type": "MD"
        },
        "id": "8MdaSJEa2Owh"
      },
      "source": [
        "**This generate function takes a prompt as input, encodes it using the tokenizer, generates output text based on the prompt using the model, and finally decodes and prints the generated text.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "8BC5pRp1jxjR0cUEek45Uc",
          "report_properties": {
            "rowId": "gJfhcggvZJMXpoq8dVa7nG"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:25.914519Z",
          "iopub.status.busy": "2023-06-04T17:49:25.913716Z",
          "iopub.status.idle": "2023-06-04T17:49:25.922504Z",
          "shell.execute_reply": "2023-06-04T17:49:25.921469Z",
          "shell.execute_reply.started": "2023-06-04T17:49:25.914478Z"
        },
        "id": "Wr2jmFbN2Owi"
      },
      "outputs": [],
      "source": [
        "def generate(prompt):\n",
        "    # Encode the prompt using the tokenizer\n",
        "    inputs = tokenizer.encode_plus(prompt, return_tensors='pt')\n",
        "    # Generate output text based on the prompt using the model\n",
        "    output = model.generate(**inputs,max_length=256,do_sample=True,pad_token_id=50259)\n",
        "    # Decode and print the generated text\n",
        "    print(tokenizer.decode(output[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "Hpx7W2fGKYcSW9SNB3AQbH",
          "report_properties": {
            "rowId": "9WQc0pdI3a2ISJIvj7WaSe"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:25.925120Z",
          "iopub.status.busy": "2023-06-04T17:49:25.924267Z",
          "iopub.status.idle": "2023-06-04T17:49:25.935727Z",
          "shell.execute_reply": "2023-06-04T17:49:25.934648Z",
          "shell.execute_reply.started": "2023-06-04T17:49:25.925079Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZrA18QT2Owi",
        "outputId": "7b876a06-2945-4198-fe51-73db0c95d25b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bos_token': '<|startoftext|>',\n",
              " 'eos_token': '<|endoftext|>',\n",
              " 'unk_token': '<|unknown|>',\n",
              " 'pad_token': '<|pad|>'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Get the special tokens map from the tokenizer\n",
        "tokenizer.special_tokens_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "si2hOB35r5Vu85YucgYCIx",
          "report_properties": {
            "rowId": "gt0jp8cQL8rXtxqw6bTi7p"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:25.938254Z",
          "iopub.status.busy": "2023-06-04T17:49:25.937504Z",
          "iopub.status.idle": "2023-06-04T17:49:25.947341Z",
          "shell.execute_reply": "2023-06-04T17:49:25.946232Z",
          "shell.execute_reply.started": "2023-06-04T17:49:25.938215Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GySjScL32Owi",
        "outputId": "3072b678-de71-4c9c-f86d-270bf963dec1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[50257]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "tokenizer.convert_tokens_to_ids(['<|startoftext|>'],)# Convert the empty token to its corresponding token ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true,
          "node_id": "M7HsbnsRDKwFSXl3a5UW3e",
          "type": "MD"
        },
        "id": "5yF4uaf92Owi"
      },
      "source": [
        "## **Load data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "0s8H37ECP8ErbIXyNstLj7",
          "report_properties": {
            "rowId": "TFJs9rPdjEhQtOjSJZkrJ8"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:25.949771Z",
          "iopub.status.busy": "2023-06-04T17:49:25.948988Z",
          "iopub.status.idle": "2023-06-04T17:49:26.234274Z",
          "shell.execute_reply": "2023-06-04T17:49:26.233183Z",
          "shell.execute_reply.started": "2023-06-04T17:49:25.949735Z"
        },
        "id": "WD1pWKWG2Owi"
      },
      "outputs": [],
      "source": [
        "# Read the CSV file into a pandas DataFrame called 'clean'\n",
        "clean = pd.read_csv('/content/drive/MyDrive/dataset/Food_Recipe_Dataset.csv')\n",
        "# Shuffle the rows of the DataFrame\n",
        "clean = clean.sample(frac=1)\n",
        "# Reset the index of the DataFrame\n",
        "clean.reset_index(drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "MiV11DM8ADEZuqFz896ZFK",
          "report_properties": {
            "rowId": "GdCRIGhPC9yUQvSOW2paB6"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:26.236479Z",
          "iopub.status.busy": "2023-06-04T17:49:26.236061Z",
          "iopub.status.idle": "2023-06-04T17:49:26.251364Z",
          "shell.execute_reply": "2023-06-04T17:49:26.250100Z",
          "shell.execute_reply.started": "2023-06-04T17:49:26.236439Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMuwFtNY2Owi",
        "outputId": "adaabe7f-f2f9-4cee-e6e0-4dcc9d802b55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Indian' 'Konkan' 'Rajasthani' 'Andhra' 'Continental' 'Italian Recipes'\n",
            " 'South Indian Recipes' 'Fusion' 'Punjabi' 'North Indian Recipes'\n",
            " 'Middle Eastern' 'Indo Chinese' 'Parsi Recipes' 'Goan Recipes'\n",
            " 'Gujarati Recipes\\ufeff' 'Kashmiri' 'Bengali Recipes' 'Sindhi' 'Mexican'\n",
            " 'World Breakfast' 'Chettinad' 'Oriya Recipes' 'North East India Recipes'\n",
            " 'Asian' 'Maharashtrian Recipes' 'Kerala Recipes' 'French' 'Mediterranean'\n",
            " 'Thai' 'Hyderabadi' 'Mangalorean' 'Tamil Nadu' 'Coorg' 'Karnataka'\n",
            " 'North Karnataka' 'Mughlai' 'Jewish' 'Appetizer' 'Cantonese' 'European'\n",
            " 'Uttar Pradesh' 'Awadhi' 'Jharkhand' 'Nepalese' 'South Karnataka'\n",
            " 'Pakistani' 'Assamese' 'Udupi' 'Uttarakhand-North Kumaon' 'African'\n",
            " 'Japanese' 'Coastal Karnataka' 'Chinese' 'Himachal' 'Malvani' 'Lucknowi'\n",
            " 'Greek' 'Brunch' 'Bihari' 'Afghan' 'Sri Lankan' 'Hunan' 'Malabar'\n",
            " 'Korean' 'Vietnamese' 'Caribbean' 'Arab' 'Dessert' 'Indonesian'\n",
            " 'American' 'Snack' 'Malaysian' 'British' 'Sichuan' 'Lunch' 'Side Dish'\n",
            " 'Dinner' 'Nagaland' 'Haryana' 'Burmese' 'Kongunadu' 'Shandong']\n"
          ]
        }
      ],
      "source": [
        "print(clean['Cuisine'].unique())#unique cuisine found in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "JSa2QSNCspdRP5SFgTJzD2",
          "report_properties": {
            "rowId": "PK7tYyUPIqM9m5y00CqQn8"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:26.254506Z",
          "iopub.status.busy": "2023-06-04T17:49:26.253270Z",
          "iopub.status.idle": "2023-06-04T17:49:26.260488Z",
          "shell.execute_reply": "2023-06-04T17:49:26.259207Z",
          "shell.execute_reply.started": "2023-06-04T17:49:26.254466Z"
        },
        "id": "3teg6RmI2Owj"
      },
      "outputs": [],
      "source": [
        "def print_recipe(idx):\n",
        "    # Print the ingredients and instructions of the recipe at the specified index.\n",
        "    print(f\"{clean['ingredients'][idx]}\\n\\n{clean['instructions'][idx]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true,
          "node_id": "3tjYavlVB0vwzMXfk0HLv6",
          "type": "MD"
        },
        "id": "UI2_yhzP2Owj"
      },
      "source": [
        "**the form_string function that takes an ingredient and an instruction as inputs and returns a formatted string combining them.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "Bo9cFGWDSrgwojp6haq42u",
          "report_properties": {
            "rowId": "uia0dwjWoYfHu12hiTqQ3i"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:26.262880Z",
          "iopub.status.busy": "2023-06-04T17:49:26.261981Z",
          "iopub.status.idle": "2023-06-04T17:49:26.270366Z",
          "shell.execute_reply": "2023-06-04T17:49:26.269228Z",
          "shell.execute_reply.started": "2023-06-04T17:49:26.262833Z"
        },
        "id": "-6T1MEui2Owj"
      },
      "outputs": [],
      "source": [
        "def form_string(ingredient,instruction):\n",
        "    # Formulate the string combining the ingredients and instructions\n",
        "    s = f\"<|startoftext|>Ingredients:\\n{ingredient.strip()}\\n\\nInstructions:\\n{instruction.strip()}<|endoftext|>\"\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "OVlWECAz2VwuW12BUR1xN7",
          "report_properties": {
            "rowId": "2dFxZsU0RcsYES7OG6gYin"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:26.276391Z",
          "iopub.status.busy": "2023-06-04T17:49:26.276077Z",
          "iopub.status.idle": "2023-06-04T17:49:26.406972Z",
          "shell.execute_reply": "2023-06-04T17:49:26.405961Z",
          "shell.execute_reply.started": "2023-06-04T17:49:26.276363Z"
        },
        "id": "ufyWeX3R2Owj"
      },
      "outputs": [],
      "source": [
        "# Apply the form_string function to each row in the clean DataFrame\n",
        "# using 'TranslatedIngredients' and 'TranslatedInstructions' columns as inputs\n",
        "data = clean.apply(lambda x:form_string(x['TranslatedIngredients'],x['TranslatedInstructions']),axis=1).to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "G4AipDPe16LXpBAtJRqEdX",
          "report_properties": {
            "rowId": "r4QuqTNHfMCSqDX5dvneeL"
          },
          "type": "MD"
        },
        "id": "NJoCoSLx2Owj"
      },
      "source": [
        "https://towardsdatascience.com/guide-to-fine-tuning-text-generation-models-gpt-2-gpt-neo-and-t5-dc5de6b3bc5e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true,
          "node_id": "NXW8ZGxhh8G94J1WVC5QDY",
          "type": "MD"
        },
        "id": "ackdENOb2Owj"
      },
      "source": [
        "## **splits the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "Zx9QHYJ09T811FHzQzM0A2",
          "report_properties": {
            "rowId": "mAlaxpQC3a1A8rVYVx0Cvq"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:26.409133Z",
          "iopub.status.busy": "2023-06-04T17:49:26.408554Z",
          "iopub.status.idle": "2023-06-04T17:49:26.415065Z",
          "shell.execute_reply": "2023-06-04T17:49:26.413964Z",
          "shell.execute_reply.started": "2023-06-04T17:49:26.409092Z"
        },
        "id": "HWCsmUo42Owj"
      },
      "outputs": [],
      "source": [
        "# Set the proportion of data to be used for training\n",
        "train_size = 0.85\n",
        "# Calculate the length of the training set based on the specified train_size\n",
        "train_len = int(train_size * len(data))\n",
        "# Split the data into training and validation sets\n",
        "train_data = data[:train_len]# Contains the first train_len elements for training\n",
        "val_data = data[train_len:] # Contains the remaining elements for validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true,
          "node_id": "0LMJufRJqHbOr2hUIwgywa",
          "type": "MD"
        },
        "id": "mhg_g9zl2Owj"
      },
      "source": [
        "**Defines a RecipeDataset class, which is a PyTorch dataset for working with recipe data. It takes a data list as input during initialization.**\n",
        "\n",
        "**The RecipeDataset class has three main methods:**\n",
        "\n",
        "1 - Initializes the dataset by processing the data list. It tokenizes and encodes each item in the data list using the tokenizer. The resulting input_ids and attention_masks are stored in separate lists self.input_ids and self.attn_masks.**\n",
        "\n",
        "2 - Returns the total number of items in the dataset, which is the length of the data list.\n",
        "\n",
        "3 - Returns the input_ids and attention_masks for the item at the given index idx."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "1ps3GeWplJLJaes9eGpjld",
          "report_properties": {
            "rowId": "lANwUfnsjpRhJe2HfQKJiz"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:26.417364Z",
          "iopub.status.busy": "2023-06-04T17:49:26.416717Z",
          "iopub.status.idle": "2023-06-04T17:49:26.428370Z",
          "shell.execute_reply": "2023-06-04T17:49:26.427288Z",
          "shell.execute_reply.started": "2023-06-04T17:49:26.417324Z"
        },
        "id": "MPBk_xhy2Owk"
      },
      "outputs": [],
      "source": [
        "class RecipeDataset:\n",
        "    def __init__(self,data):\n",
        "        self.data = data\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        # Iterate over the data and process each item\n",
        "        for item in tqdm(data):\n",
        "            # Tokenize and encode the item using the tokenizer\n",
        "            encodings = tokenizer.encode_plus(item,\n",
        "                                              truncation=True,\n",
        "                                              padding='max_length',\n",
        "                                              max_length=1024,\n",
        "                                              return_tensors='pt'\n",
        "                                             )\n",
        "            # Extract and store the input_ids and attention_masks\n",
        "            self.input_ids.append(torch.squeeze(encodings['input_ids'],0))\n",
        "            self.attn_masks.append(torch.squeeze(encodings['attention_mask'],0))\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the total number of items in the dataset\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        # Return the input_ids and attention_masks for the item at the given index\n",
        "        return self.input_ids[idx], self.attn_masks[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true,
          "node_id": "l0rKvNSkAMTK8vQeWWi3U2",
          "type": "MD"
        },
        "id": "pY3yR_WY2Owk"
      },
      "source": [
        "**collate_fn function collate a batch of data samples in the custom RecipeDataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "HGnUeweCYmVMeVEE63do6H",
          "report_properties": {
            "rowId": "eCCLnfRmbtcC4UAr1mGoAB"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:26.431802Z",
          "iopub.status.busy": "2023-06-04T17:49:26.431345Z",
          "iopub.status.idle": "2023-06-04T17:49:26.443661Z",
          "shell.execute_reply": "2023-06-04T17:49:26.442615Z",
          "shell.execute_reply.started": "2023-06-04T17:49:26.431765Z"
        },
        "id": "pN6TYLfZ2Owk"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    # Stack the input_ids, attention_mask, and labels tensors in the batch\n",
        "    return {\n",
        "        'input_ids': torch.stack([item[0] for item in batch]),\n",
        "        'attention_mask': torch.stack([item[1] for item in batch]),\n",
        "        'labels': torch.stack([item[0] for item in batch])\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "0EqTkPFyiRJFcjKlI4Osml",
          "report_properties": {
            "rowId": "ZacWPRPonxY4DecLiVPBqD"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:26.446592Z",
          "iopub.status.busy": "2023-06-04T17:49:26.445842Z",
          "iopub.status.idle": "2023-06-04T17:49:35.959667Z",
          "shell.execute_reply": "2023-06-04T17:49:35.958640Z",
          "shell.execute_reply.started": "2023-06-04T17:49:26.446538Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "8c6f52cb2d37429dacb79d726a0556a1",
            "bdace877c1614accbf4ee043d149c800",
            "7ee26bef3f1f4d87b35789e7044153dd",
            "a76f404c50ce40ab8ec5c132c34f6175",
            "c252330b3aab40098567298479275da5",
            "f33a4c8a8cc44f27acd92ae381478a9f",
            "a110e1b6580741b482933e0302bec05d",
            "5a7460a434d74d46947b02ae49d67c0d",
            "b1ce9a591d934009a19be74e4be1469e",
            "e655464361894404aa590354bffc18fe",
            "bc7c923d9ef04b19b6e4cc3a6d73058e",
            "80a784110d5a42cc8fdb7b1d941ac6d9",
            "951c6bb1cc2d462da30d14c64596d8d8",
            "d5720678db414c0fa33554ab89ee1615",
            "04ecdd6e77d34e5eb6a676b859128a7b",
            "26a5d9ba30c64467b96432d05ced9c5c",
            "396ed971e78d42a9a836407c0043c5b0",
            "aac799e4abf540438906bddf925e7b25",
            "95b4d36019c34561b20cf13cfb00df73",
            "49280576f7e64ceab8c40fdf53e4c336",
            "16ff2734f6a24e5ba8201744e6a56b1c",
            "3780f620bca6488d96d3852fa144a05a"
          ]
        },
        "id": "9v8RjKi-2Owk",
        "outputId": "702ec6b3-27db-445a-ab92-d141f0d1dc8a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5047 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c6f52cb2d37429dacb79d726a0556a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/891 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80a784110d5a42cc8fdb7b1d941ac6d9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Initialize train_ds with the training data\n",
        "train_ds = RecipeDataset(train_data)\n",
        "# Initialize val_ds with the validation data\n",
        "val_ds = RecipeDataset(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "8qVuuIRmBqNJNAXvmV6Ygz",
          "report_properties": {
            "rowId": "Clbywyj8TYmhDKKnYzUeBl"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:35.962605Z",
          "iopub.status.busy": "2023-06-04T17:49:35.961404Z",
          "iopub.status.idle": "2023-06-04T17:49:36.073842Z",
          "shell.execute_reply": "2023-06-04T17:49:36.072746Z",
          "shell.execute_reply.started": "2023-06-04T17:49:35.962559Z"
        },
        "id": "9inHR7zl2Owk"
      },
      "outputs": [],
      "source": [
        "# Initialize args with the training arguments and settings\n",
        "args = TrainingArguments(\n",
        "    output_dir=model_save_path,  # Directory to save the trained model\n",
        "    per_device_train_batch_size=2,  # Batch size for training on each device\n",
        "    per_device_eval_batch_size=2,  # Batch size for evaluation on each device\n",
        "    gradient_accumulation_steps=2,  # Number of steps to accumulate gradients before performing optimization\n",
        "    report_to='none',  # Disable reporting of training progress\n",
        "    num_train_epochs=3,  # Number of training epochs\n",
        "    save_strategy='no'  # Disable saving of checkpoints during training\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "me4BB8wpXJ5x6VDgLMh9qA",
          "report_properties": {
            "rowId": "bONIL9KJ0AZNBqP3UbnwKN"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:36.075627Z",
          "iopub.status.busy": "2023-06-04T17:49:36.075238Z",
          "iopub.status.idle": "2023-06-04T17:49:36.084615Z",
          "shell.execute_reply": "2023-06-04T17:49:36.083378Z",
          "shell.execute_reply.started": "2023-06-04T17:49:36.075590Z"
        },
        "id": "bNCS1XQN2Owk"
      },
      "outputs": [],
      "source": [
        "# Initialize the optimizer using the AdamW algorithm\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "# Initialize the scheduler using the CosineAnnealingWarmRestarts method\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optim, 20, eta_min=1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "c0veGgKZQRpOiPTSUJ18SC",
          "report_properties": {
            "rowId": "6ApWhjBj1HZyZ4ouxPloYp"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:36.086814Z",
          "iopub.status.busy": "2023-06-04T17:49:36.086191Z",
          "iopub.status.idle": "2023-06-04T17:49:41.635498Z",
          "shell.execute_reply": "2023-06-04T17:49:41.634421Z",
          "shell.execute_reply.started": "2023-06-04T17:49:36.086775Z"
        },
        "id": "UN-g3iR02Owk"
      },
      "outputs": [],
      "source": [
        "# Initialize the trainer object for model training\n",
        "trainer = Trainer(\n",
        "    model,  # The model to be trained\n",
        "    args,  # The training arguments and settings\n",
        "    train_dataset=train_ds,  # The training dataset\n",
        "    eval_dataset=val_ds,  # The validation dataset\n",
        "    data_collator=collate_fn,  # The collate function for batching the data\n",
        "    optimizers=(optim, scheduler)  # The optimizer and scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "sl23zKRmctgYMUya6FZc4B",
          "report_properties": {
            "rowId": "5ulOhjA5i9UoecXvi2Bjy3"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T17:49:41.637808Z",
          "iopub.status.busy": "2023-06-04T17:49:41.637025Z",
          "iopub.status.idle": "2023-06-04T18:41:48.568763Z",
          "shell.execute_reply": "2023-06-04T18:41:48.567632Z",
          "shell.execute_reply.started": "2023-06-04T17:49:41.637768Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "A2ZuP3Vb2Owk",
        "outputId": "63da0683-c854-4b1a-cc9c-a141d874454b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-d8e2498cb65f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#starts the training process using the trainer object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1885\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1886\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2215\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2216\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2218\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3262\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3263\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3264\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3265\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3266\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1300\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1303\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1114\u001b[0m                 )\n\u001b[1;32m   1115\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m   1117\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         attn_outputs = self.attn(\n\u001b[0m\u001b[1;32m    615\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upcast_and_reordered_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36m_attn\u001b[0;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_attn_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer.train()#starts the training process using the trainer object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "FWnUq5jQCqwsyz2yYQUu7G",
          "report_properties": {
            "rowId": "mds9oDU6Imo0IjhH8M6PSD"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T18:41:48.571414Z",
          "iopub.status.busy": "2023-06-04T18:41:48.570409Z",
          "iopub.status.idle": "2023-06-04T18:41:49.632405Z",
          "shell.execute_reply": "2023-06-04T18:41:49.631369Z",
          "shell.execute_reply.started": "2023-06-04T18:41:48.571372Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "QjkLs_3X2Owl",
        "outputId": "9ffaa068-640f-491d-ef67-8887133aeffd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bae3f8db1f55>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#to save the trained model after the training process is completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ],
      "source": [
        "trainer.save_model()#to save the trained model after the training process is completed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "2fxQzIEegt0THyC0JBVPjJ",
          "report_properties": {
            "rowId": "yI6HCY6nfsrlB3SszNiJVC"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T18:41:49.639273Z",
          "iopub.status.busy": "2023-06-04T18:41:49.636928Z",
          "iopub.status.idle": "2023-06-04T18:41:52.231128Z",
          "shell.execute_reply": "2023-06-04T18:41:52.230131Z",
          "shell.execute_reply.started": "2023-06-04T18:41:49.639236Z"
        },
        "id": "2KUG3mwi2Owl"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "rNRDH1h2zl3lBkzVF9qHnD",
          "report_properties": {
            "rowId": "0UWn53n7EfzvVJRhco5sIu"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T18:41:52.233217Z",
          "iopub.status.busy": "2023-06-04T18:41:52.232530Z",
          "iopub.status.idle": "2023-06-04T18:41:54.725203Z",
          "shell.execute_reply": "2023-06-04T18:41:54.723860Z",
          "shell.execute_reply.started": "2023-06-04T18:41:52.233176Z"
        },
        "id": "gg0Bch9X2Owl",
        "outputId": "a476046a-44e3-4c17-c205-31838e1082d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file /kaggle/working/DLProejectGPT/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"/kaggle/working/DLProejectGPT\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50260\n",
            "}\n",
            "\n",
            "loading configuration file /kaggle/working/DLProejectGPT/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"/kaggle/working/DLProejectGPT\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50260\n",
            "}\n",
            "\n",
            "loading weights file /kaggle/working/DLProejectGPT/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /kaggle/working/DLProejectGPT.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "loading file /kaggle/working/DLProejectGPT/vocab.json\n",
            "loading file /kaggle/working/DLProejectGPT/merges.txt\n",
            "loading file /kaggle/working/DLProejectGPT/tokenizer.json\n",
            "loading file /kaggle/working/DLProejectGPT/added_tokens.json\n",
            "loading file /kaggle/working/DLProejectGPT/special_tokens_map.json\n",
            "loading file /kaggle/working/DLProejectGPT/tokenizer_config.json\n"
          ]
        }
      ],
      "source": [
        "pl = pipeline(task='text-generation',model='/content/drive/MyDrive/major project')#initializes a text generation pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": true,
          "hide_output_from_viewers": true,
          "node_id": "FF0UhznC7N6of5yfJMQgKQ",
          "type": "MD"
        },
        "id": "zmIp_XPJ2Owl"
      },
      "source": [
        "**The create_prompt function takes a string of ingredients and a cuisine name as input and creates a formatted prompt string for generating a recipe.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "bpjew3G5MeTh80cRt7BM7r",
          "report_properties": {
            "rowId": "Urkx8cHztgJEeXfDUK2eSW"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T18:41:54.728058Z",
          "iopub.status.busy": "2023-06-04T18:41:54.727666Z",
          "iopub.status.idle": "2023-06-04T18:41:54.742311Z",
          "shell.execute_reply": "2023-06-04T18:41:54.739752Z",
          "shell.execute_reply.started": "2023-06-04T18:41:54.728013Z"
        },
        "id": "Wot0Xz4Y2Owo"
      },
      "outputs": [],
      "source": [
        "def create_prompt(cuisine,ingredients):\n",
        "    # Convert the ingredients to lowercase and remove leading/trailing whitespaces\n",
        "    ingredients = ','.join([x.strip().lower() for x in ingredients.split(',')])\n",
        "    # Replace commas with newline characters for better ingredient formatting\n",
        "    ingredients = ingredients.strip().replace(',', '\\n')\n",
        "    # Create the prompt string with the formatted ingredients and cuisine\n",
        "    s = f\"\\n\\nCuisine:\\n{Cuisine.value}\\n\\nIngredients:\\n{ingredients}\\n\"\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "zDoPMfLJx7rMb3rQcYVzyv",
          "report_properties": {
            "rowId": "31P9LK5YXIOPotImsWAuZX"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T18:41:54.744816Z",
          "iopub.status.busy": "2023-06-04T18:41:54.744169Z",
          "iopub.status.idle": "2023-06-04T18:45:11.016512Z",
          "shell.execute_reply": "2023-06-04T18:45:11.015443Z",
          "shell.execute_reply.started": "2023-06-04T18:41:54.744776Z"
        },
        "colab": {
          "referenced_widgets": [
            "495e763e796c48caa4f573a563b68d4f"
          ]
        },
        "id": "DE3VSYlv2Owo",
        "outputId": "9e3ff227-64be-45db-972e-93d9ad1ed3b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Want to explore new flavors? Choose your cuisine preference!\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "495e763e796c48caa4f573a563b68d4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dropdown(options=('Sindhi', 'Mexican', 'Indian', 'Tamil Nadu', 'Chettinad', 'Goan Recipes', 'North Indian Reci‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "\n",
            "Add your ingredients for a unique recipe!\n",
            "(separate them with a comma :)\n",
            " flour,sugar,cinnamon,vanilla\n"
          ]
        }
      ],
      "source": [
        "# Cusinie Selection\n",
        "print(\"Want to explore new flavors? Choose your cuisine preference!\\n\")\n",
        "Cuisine = widgets.Dropdown(options = clean['Cuisine'].unique(),\n",
        "                                value=None)\n",
        "display(Cuisine)\n",
        "\n",
        "\n",
        "# Ingredients Selection\n",
        "ingredients = [i for i in input(\"\\nAdd your ingredients for a unique recipe!\"+\n",
        "                                \"\\n(separate them with a comma :)\\n\").split()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "datalore": {
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "node_id": "18Fe7YXlxaquFRFyrLrQMC",
          "report_properties": {
            "rowId": "sFypHgKS21tXn9j5ptAC6h"
          },
          "type": "CODE"
        },
        "execution": {
          "iopub.execute_input": "2023-06-04T18:45:35.204251Z",
          "iopub.status.busy": "2023-06-04T18:45:35.203856Z",
          "iopub.status.idle": "2023-06-04T18:45:47.775010Z",
          "shell.execute_reply": "2023-06-04T18:45:47.773860Z",
          "shell.execute_reply.started": "2023-06-04T18:45:35.204218Z"
        },
        "id": "g45XqNVu2Owp",
        "outputId": "a7c3788e-165b-4172-a793-41d151f8f521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Cuisine:\n",
            "Arab\n",
            "\n",
            "Ingredients:\n",
            "flour\n",
            "sugar\n",
            "cinnamon\n",
            "vanilla\n",
            "\n",
            "1 cup raita flour, salt\n",
            "\n",
            "1 cup rice flour, 1/2 cup water, salt - as required\n",
            "\n",
            "pinch cinnamon, 1/2 cup sugar, 2 cups water, 1/2 teaspoon turmeric powder\n",
            "\n",
            "Instructions:\n",
            "To make the raita rice dough, firstly we will first make the raita.\n",
            "In a mixer, add the rice flour, salt, turmeric powder, cinnamon, sugar, water and grind to a smooth dough.\n",
            "Keep it aside.Now heat oil in a pan.\n",
            "Add cinnamon, sugar, turmeric and cook for 2 minutes.\n",
            "Once the spices start to sizzle, add the raita flour, rice flour, water and cook for 2 minutes.\n",
            "Add the remaining water and cook until the raita is cooked well.\n",
            "After 2 minutes, add the raita dough into the mixer and mix well.\n",
            "Check the salt and spice levels and adjust according to your taste.\n",
            "Serve the raita rice along with steamed rice and phulkas for a weekday meal.\n",
            "You can also serve it with phulkas for a wholesome lunch.\n"
          ]
        }
      ],
      "source": [
        "for ing in ingredients:\n",
        "    # Create a prompt using the current ingredient set and the specified cuisine\n",
        "    prompt = create_prompt(Cuisine.value,ing)\n",
        "    # Generate a recipe using the pipeline with specified parameters and print the generated recipe\n",
        "    print(pl(prompt,\n",
        "         max_new_tokens=512,\n",
        "         penalty_alpha=0.6,\n",
        "         top_k=4,\n",
        "         pad_token_id=50259\n",
        "        )[0]['generated_text'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c6f52cb2d37429dacb79d726a0556a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdace877c1614accbf4ee043d149c800",
              "IPY_MODEL_7ee26bef3f1f4d87b35789e7044153dd",
              "IPY_MODEL_a76f404c50ce40ab8ec5c132c34f6175"
            ],
            "layout": "IPY_MODEL_c252330b3aab40098567298479275da5"
          }
        },
        "bdace877c1614accbf4ee043d149c800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f33a4c8a8cc44f27acd92ae381478a9f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a110e1b6580741b482933e0302bec05d",
            "value": "100%"
          }
        },
        "7ee26bef3f1f4d87b35789e7044153dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a7460a434d74d46947b02ae49d67c0d",
            "max": 5047,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1ce9a591d934009a19be74e4be1469e",
            "value": 5047
          }
        },
        "a76f404c50ce40ab8ec5c132c34f6175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e655464361894404aa590354bffc18fe",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bc7c923d9ef04b19b6e4cc3a6d73058e",
            "value": "‚Äá5047/5047‚Äá[00:11&lt;00:00,‚Äá479.37it/s]"
          }
        },
        "c252330b3aab40098567298479275da5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f33a4c8a8cc44f27acd92ae381478a9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a110e1b6580741b482933e0302bec05d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a7460a434d74d46947b02ae49d67c0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1ce9a591d934009a19be74e4be1469e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e655464361894404aa590354bffc18fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc7c923d9ef04b19b6e4cc3a6d73058e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80a784110d5a42cc8fdb7b1d941ac6d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_951c6bb1cc2d462da30d14c64596d8d8",
              "IPY_MODEL_d5720678db414c0fa33554ab89ee1615",
              "IPY_MODEL_04ecdd6e77d34e5eb6a676b859128a7b"
            ],
            "layout": "IPY_MODEL_26a5d9ba30c64467b96432d05ced9c5c"
          }
        },
        "951c6bb1cc2d462da30d14c64596d8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_396ed971e78d42a9a836407c0043c5b0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_aac799e4abf540438906bddf925e7b25",
            "value": "100%"
          }
        },
        "d5720678db414c0fa33554ab89ee1615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95b4d36019c34561b20cf13cfb00df73",
            "max": 891,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49280576f7e64ceab8c40fdf53e4c336",
            "value": 891
          }
        },
        "04ecdd6e77d34e5eb6a676b859128a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16ff2734f6a24e5ba8201744e6a56b1c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3780f620bca6488d96d3852fa144a05a",
            "value": "‚Äá891/891‚Äá[00:02&lt;00:00,‚Äá469.57it/s]"
          }
        },
        "26a5d9ba30c64467b96432d05ced9c5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "396ed971e78d42a9a836407c0043c5b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aac799e4abf540438906bddf925e7b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95b4d36019c34561b20cf13cfb00df73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49280576f7e64ceab8c40fdf53e4c336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16ff2734f6a24e5ba8201744e6a56b1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3780f620bca6488d96d3852fa144a05a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}